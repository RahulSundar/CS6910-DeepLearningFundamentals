{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_ObjectDetection_unbalanced_sweep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsLNDUwvGPVGWkXrg1+mTl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulSundar/CS6910-DeepLearningFundamentals/blob/main/Assignment2/Assignment2_ObjectDetection_unbalanced_sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cykm-daIJXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd00897-e393-4cdd-bddd-95e2b77661b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oqxnJgOIJO8"
      },
      "source": [
        "import os, sys\n",
        "sys.path.append(\n",
        "\"/content/drive/MyDrive/CS6910/Assignment2\"\n",
        ")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cGzCjsKIJAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823064a4-8cfd-4120-dad5-3fe3c6279ad2"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.25)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPECnwAsHjne"
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "# keras pre-trained models\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2 as IRV2\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Conv2D, BatchNormalization, MaxPooling2D, Activation \n",
        "from tensorflow.keras.models import Sequential,  Model\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "class ObjectDetection():\n",
        "\n",
        "    def __init__(self, IMG_SIZE, modelConfigDict, using_pretrained_model = False, base_model = \"IRV2\" ):\n",
        "        \n",
        "        self.num_hidden_cnn_layers= modelConfigDict[\"num_hidden_cnn_layers\"]\n",
        "        self.activation = modelConfigDict[\"activation\"]\n",
        "        self.batch_normalization = modelConfigDict[\"batch_normalization\"]\n",
        "        self.filter_distribution = modelConfigDict[\"filter_distribution\"]\n",
        "        self.filter_size = modelConfigDict[\"filter_size\"]\n",
        "        self.number_of_filters_base  = modelConfigDict[\"number_of_filters_base\"]\n",
        "        self.initializer = modelConfigDict[\"initializer\"]\n",
        "        self.dropout_fraction = modelConfigDict[\"dropout_fraction\"]\n",
        "        self.pool_size = modelConfigDict[\"pool_size\"]\n",
        "        self.padding = modelConfigDict[\"padding\"]\n",
        "        self.dense_neurons = modelConfigDict[\"dense_neurons\"]\n",
        "        self.num_classes = modelConfigDict[\"num_classes\"]\n",
        "        self.optimizer = modelConfigDict[\"optimizer\"]\n",
        "\n",
        "        BASE_MODELS = {\n",
        "                          \"IRV2\" : IRV2,\n",
        "                          \"IV3\" : InceptionV3,\n",
        "                          \"RN50\" : ResNet50,\n",
        "                          \"XCPTN\" : Xception\n",
        "                      }      \n",
        "        \n",
        "        if using_pretrained_model == True:\n",
        "            self.base_model = base_model\n",
        "            if self.base_model == \"RN50\":\n",
        "                self.IMG_HEIGHT = 224\n",
        "                self.IMG_WIDTH = 224\n",
        "            else:\n",
        "                self.IMG_HEIGHT = IMG_SIZE[0]\n",
        "                self.IMG_WIDTH = IMG_SIZE[1]        \n",
        "\n",
        "        self.IMG_HEIGHT = IMG_SIZE[0]\n",
        "        self.IMG_WIDTH = IMG_SIZE[1]        \n",
        "         \n",
        "        self.input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)\n",
        "\n",
        "\n",
        "    def build_cnndropmodel(self):\n",
        "        keras.backend.clear_session()\n",
        "        model = Sequential()\n",
        "        \n",
        "        #First CNN layer connecting to input layer\n",
        "        model.add(Conv2D(self.number_of_filters_base, self.filter_size, kernel_regularizer='l2',padding = self.padding, input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "        model.add(Activation(self.activation))\n",
        "        \n",
        "        #batch_normalisation\n",
        "        if self.batch_normalization: model.add(BatchNormalization())\n",
        "        #max pooling\n",
        "        model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "        if self.dropout_fraction != None:\n",
        "            model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        for i in range(self.num_hidden_cnn_layers-1):\n",
        "            #i+2th Convolutional Layer\n",
        "        \n",
        "            ## Standard filter distribution - same number of filters in all Convolutional layers\n",
        "            if self.filter_distribution == \"standard\":\n",
        "                model.add(Conv2D(self.number_of_filters_base, self.filter_size,kernel_regularizer='l2', padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            ## Double filter distribution - double number of filters in each Convolutional layers\n",
        "            elif self.filter_distribution == \"double\":\n",
        "                model.add(Conv2D(2**(i+1)*self.number_of_filters_base, self.filter_size, kernel_regularizer='l2',padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            ## Halve the filter size in each successive convolutional layers\n",
        "            elif self.filter_distribution == \"half\":\n",
        "                model.add(Conv2D(int(self.number_of_filters_base/2**(i+1)), self.filter_size, kernel_regularizer='l2',padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            model.add(Activation(self.activation))\n",
        "        \n",
        "            if self.batch_normalization: model.add(BatchNormalization())\n",
        "        \n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "            if self.dropout_fraction != None:\n",
        "                model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        \n",
        "        #Final densely connected layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(self.dense_neurons, activation = self.activation, kernel_regularizer='l2', kernel_initializer = self.initializer))\n",
        "        model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "        \n",
        "        #model.compile(optimizer=self.optimizer,\n",
        "        #      loss='categorical_crossentropy',\n",
        "        #      metrics=['accuracy'])\n",
        "        return model      \n",
        "        \n",
        "    def build_cnndropmodel2(self):\n",
        "        keras.backend.clear_session()\n",
        "        model = Sequential()\n",
        "        \n",
        "        #First CNN layer connecting to input layer\n",
        "        model.add(Conv2D(self.number_of_filters_base, self.filter_size, kernel_regularizer='l2',padding = self.padding, input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "        model.add(Activation(self.activation))\n",
        "        \n",
        "        #batch_normalisation\n",
        "        if self.batch_normalization: model.add(BatchNormalization())\n",
        "        #max pooling\n",
        "        model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "        if self.dropout_fraction != None:\n",
        "            model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        for i in range(self.num_hidden_cnn_layers-1):\n",
        "            #i+2th Convolutional Layer\n",
        "        \n",
        "            ## Standard filter distribution - same number of filters in all Convolutional layers\n",
        "            if self.filter_distribution == \"standard\":\n",
        "                model.add(Conv2D(self.number_of_filters_base, self.filter_size,kernel_regularizer='l2', padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            ## Double filter distribution - double number of filters in each Convolutional layers\n",
        "            elif self.filter_distribution == \"double\":\n",
        "                model.add(Conv2D(2**(i+1)*self.number_of_filters_base, self.filter_size, kernel_regularizer='l2',padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            ## Halve the filter size in each successive convolutional layers\n",
        "            elif self.filter_distribution == \"half\":\n",
        "                model.add(Conv2D(int(self.number_of_filters_base/2**(i+1)), self.filter_size, kernel_regularizer='l2',padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            model.add(Activation(self.activation))\n",
        "        \n",
        "            if self.batch_normalization: model.add(BatchNormalization())\n",
        "        \n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "            if self.dropout_fraction != None:\n",
        "                model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        \n",
        "        #Final densely connected layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(self.dense_neurons, activation = self.activation, kernel_regularizer='l2', kernel_initializer = self.initializer))\n",
        "        if self.dropout_fraction != None:\n",
        "            model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "        \n",
        "        #model.compile(optimizer=self.optimizer,\n",
        "        #      loss='categorical_crossentropy',\n",
        "        #      metrics=['accuracy'])\n",
        "        return model      \n",
        "      \n",
        "    def build_cnnmodelsimple(self):\n",
        "        keras.backend.clear_session()\n",
        "        model = Sequential()\n",
        "        \n",
        "        #First CNN layer connecting to input layer\n",
        "        model.add(Conv2D(self.number_of_filters_base, self.filter_size, input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "        model.add(Activation(self.activation))\n",
        "        \n",
        "        #batch_normalisation\n",
        "        if self.batch_normalization: model.add(BatchNormalization())\n",
        "        #max pooling\n",
        "        model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "        for i in range(self.num_hidden_cnn_layers-1):\n",
        "            #i+2th Convolutional Layer\n",
        "        \n",
        "            ## Standard filter distribution - same number of filters in all Convolutional layers\n",
        "            if self.filter_distribution == \"standard\":\n",
        "                model.add(Conv2D(self.number_of_filters_base, self.filter_size))\n",
        "        \n",
        "            ## Double filter distribution - double number of filters in each Convolutional layers\n",
        "            elif self.filter_distribution == \"double\":\n",
        "                model.add(Conv2D(2**(i+1)*self.number_of_filters_base, self.filter_size))\n",
        "        \n",
        "            ## Halve the filter size in each successive convolutional layers\n",
        "            elif self.filter_distribution == \"half\":\n",
        "                model.add(Conv2D(int(self.number_of_filters_base/2**(i+1)), self.filter_size))\n",
        "        \n",
        "            model.add(Activation(self.activation))\n",
        "        \n",
        "            if self.batch_normalization: model.add(BatchNormalization())\n",
        "        \n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "        \n",
        "        #Final densely connected layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(self.dense_neurons, activation = 'sigmoid'))\n",
        "        if self.dropout_fraction != None:\n",
        "            model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "        \n",
        "        #model.compile(optimizer=self.optimizer,\n",
        "        #      loss='categorical_crossentropy',\n",
        "        #      metrics=['accuracy'])\n",
        "        return model \n",
        "        \n",
        "    def build_cnnmodel(self):\n",
        "        keras.backend.clear_session()\n",
        "        model = Sequential()\n",
        "        \n",
        "        #First CNN layer connecting to input layer\n",
        "        model.add(Conv2D(self.number_of_filters_base, self.filter_size, kernel_regularizer='l2',padding = self.padding, input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "        model.add(Activation(self.activation))\n",
        "        \n",
        "        #batch_normalisation\n",
        "        if self.batch_normalization: model.add(BatchNormalization())\n",
        "        #max pooling\n",
        "        model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "        for i in range(self.num_hidden_cnn_layers-1):\n",
        "            #i+2th Convolutional Layer\n",
        "        \n",
        "            ## Standard filter distribution - same number of filters in all Convolutional layers\n",
        "            if self.filter_distribution == \"standard\":\n",
        "                model.add(Conv2D(self.number_of_filters_base, self.filter_size,kernel_regularizer='l2', padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            ## Double filter distribution - double number of filters in each Convolutional layers\n",
        "            elif self.filter_distribution == \"double\":\n",
        "                model.add(Conv2D(2**(i+1)*self.number_of_filters_base, self.filter_size, kernel_regularizer='l2',padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            ## Halve the filter size in each successive convolutional layers\n",
        "            elif self.filter_distribution == \"half\":\n",
        "                model.add(Conv2D(int(self.number_of_filters_base/2**(i+1)), self.filter_size, kernel_regularizer='l2',padding = self.padding, kernel_initializer = self.initializer))\n",
        "        \n",
        "            model.add(Activation(self.activation))\n",
        "        \n",
        "            if self.batch_normalization: model.add(BatchNormalization())\n",
        "        \n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "        \n",
        "        #Final densely connected layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(self.dense_neurons, activation = 'sigmoid', kernel_regularizer='l2'))\n",
        "        if self.dropout_fraction != None:\n",
        "            model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "        model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "        \n",
        "        #model.compile(optimizer=self.optimizer,\n",
        "        #      loss='categorical_crossentropy',\n",
        "        #      metrics=['accuracy'])\n",
        "        return model      \n",
        "        \n",
        "        \n",
        "    def load_pretrained_model(self):\n",
        "        base_model = BASE_MODELS[self.base_model_name]\n",
        "        base = base_model(weights='imagenet', include_top=False)\n",
        "        x = base.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(self.dense_neurons, activation='relu')(x)\n",
        "        guesses = Dense(self.num_classes, activation='softmax')(x)\n",
        "        model = Model(inputs=base.input, outputs=guesses)\n",
        "\n",
        "        # freeze all base layers\n",
        "        for layer in base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        #model.compile(optimizer=self.optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        " "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og5Ds0aQIHWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934cb27d-3bca-4466-e84a-3aa00b127843"
      },
      "source": [
        "# data preprocessing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "\n",
        "#wandb logging\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "  # Invalid device or cannot modify virtual devices once initialized.\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#data pre processing\n",
        "\n",
        "data_augmentation = False\n",
        "\n",
        "IMG_SIZE = (128,128)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "if data_augmentation == True:\n",
        "\n",
        "#Faster Alternative\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            validation_split = 0.1,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False\n",
        "            )\n",
        "else:\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split = 0.1)\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/CS6910/Assignment2/inaturalist_12K/train',\n",
        "    subset='training',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle = True,\n",
        "     seed = 123)\n",
        "    \n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/CS6910/Assignment2/inaturalist_12K/train',\n",
        "        target_size=IMG_SIZE,\n",
        "        subset = 'validation',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle = True,\n",
        "         seed = 123)\n",
        "\n",
        "\n",
        "        \n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/CS6910/Assignment2/inaturalist_12K/val',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle = True,\n",
        "         seed = 123)\n",
        "\n",
        "''' \n",
        "#sweep config\n",
        "sweep_config = {\n",
        "  \"name\": \"Bayesian Sweep\",\n",
        "  \"method\": \"bayes\",\n",
        "  \"metric\":{\n",
        "  \"name\": \"validationaccuracy\",\n",
        "  \"goal\": \"maximize\"\n",
        "  },\n",
        "  'early_terminate': {\n",
        "        'type':'hyperband',\n",
        "        'min_iter': [3],\n",
        "        's': [2]\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \n",
        "        \"activation\":{\n",
        "            \"values\": [\"relu\", \"elu\"]\n",
        "        },\n",
        "                    \n",
        "        \"batch_size\": {\n",
        "            \"values\": [32, 64]\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\": [\"sgd\", \"adam\", \"rmsprop\"]\n",
        "        },\n",
        "        \"batch_normalization\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "        \"number_of_filters_base\": {\n",
        "            \"values\": [32, 64]\n",
        "        },\n",
        "        \"dense_neurons\": {\n",
        "            \"values\": [32, 64]\n",
        "        },\n",
        "        \"dropout_fraction\": {\n",
        "            \"values\": [0.2,0.3]\n",
        "        },        \n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config,project='CS6910-DeepLearningFundamentals-Assignment1', entity='rahulsundar')\n",
        "\n",
        "'''\n",
        "\n",
        "#train function\n",
        "def train():\n",
        "\n",
        "        \n",
        "    config_defaults = dict(\n",
        "            num_hidden_cnn_layers = 5 ,\n",
        "            activation = 'relu',\n",
        "            batch_normalization = True,\n",
        "            filter_distribution = \"double\" ,\n",
        "            filter_size = (3,3),\n",
        "            number_of_filters_base  = 32,\n",
        "            initializer = 'he_uniform',\n",
        "            dropout_fraction = None,\n",
        "            pool_size = (2,2),\n",
        "            padding = 'same',\n",
        "            dense_neurons = 128,\n",
        "            num_classes = 10,\n",
        "            optimizer = 'adam',\n",
        "            epochs = 5,\n",
        "            batch_size = 32, \n",
        "            img_size = IMG_SIZE\n",
        "        ) \n",
        "    wandb.init(project = 'CS6910-Assignment2-CNNs', config = config_defaults,entity='rahulsundar')\n",
        "    CONFIG = wandb.config\n",
        "        \n",
        "\n",
        "\n",
        "    wandb.run.name = \"OBJDET_\" + str(CONFIG.num_hidden_cnn_layers) + \"_dn_\" + str(CONFIG.dense_neurons) + \"_opt_\" + CONFIG.optimizer + \"_dro_\" + str(CONFIG.dropout_fraction) + \"_bs_\"+str(CONFIG.batch_size) + \"_fd_\" + CONFIG.filter_distribution\n",
        "\n",
        "    def myprint(s, path = '/content/drive/MyDrive/CS6910/Assignment2/TrainedModel/'+wandb.run.name):\n",
        "        with open(path+\"/mymodelsummary.txt\",'w+') as f:\n",
        "            print(s, file=f)\n",
        "            \n",
        "            \n",
        "    objDetn = ObjectDetection(CONFIG.img_size, CONFIG )\n",
        "    #model = objDetn.build_cnnmodel()\n",
        "    model = objDetn.build_cnnmodelsimple()\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=CONFIG.optimizer,  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),#'categorical_crossentropy',\n",
        "    # List of metrics to monitor\n",
        "    metrics=['accuracy'],\n",
        "    )\n",
        "  \n",
        "    history = model.fit(\n",
        "                    train_generator,\n",
        "                    steps_per_epoch = train_generator.samples // CONFIG.batch_size,\n",
        "                    validation_data = validation_generator, \n",
        "                    validation_steps = validation_generator.samples // CONFIG.batch_size,\n",
        "                    epochs = CONFIG.epochs, \n",
        "                    callbacks=[WandbCallback()]\n",
        "                    )\n",
        "\n",
        "    model.save('./TrainedModel/'+wandb.run.name)\n",
        "    model.summary(print_fn=myprint)\n",
        "    wandb.finish()\n",
        "    return model, history\n",
        "    \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9032 images belonging to 10 classes.\n",
            "Found 1001 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sJqO8m9MLj7c",
        "outputId": "2ce82b7e-c409-4c90-95c2-a0b48ba1cb54"
      },
      "source": [
        "Model, History = train()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.25<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">rose-monkey-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/rahulsundar/CS6910-Assignment2-CNNs\" target=\"_blank\">https://wandb.ai/rahulsundar/CS6910-Assignment2-CNNs</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/rahulsundar/CS6910-Assignment2-CNNs/runs/2qhozl6y\" target=\"_blank\">https://wandb.ai/rahulsundar/CS6910-Assignment2-CNNs/runs/2qhozl6y</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210410_190802-2qhozl6y</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 126, 126, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 61, 61, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,836,106\n",
            "Trainable params: 1,834,122\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            " 20/282 [=>............................] - ETA: 40:27 - loss: 2.3719 - accuracy: 0.1788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a7d276f58518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-43d65dd2ba88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                     )\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}